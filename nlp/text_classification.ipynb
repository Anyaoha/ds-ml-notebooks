{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification with NLTK \n",
    "\n",
    "- The objective of this example is to take a corpus of 'movie_reviews' from the nltk.corpus example datasets and predict whether the content in an out-of-sample review would be classified as \"Negative\" or \"Positive\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### Example\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk.tree import Tree\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk import FreqDist\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import time\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "#Jupyter Notebook Options\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Version: 3.5.2 |Anaconda 4.2.0 (x86_64)| (default, Jul  2 2016, 17:52:12) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)]\n",
      "\n",
      "/Users/tracesmith/anaconda/lib/python3.5/site-packages/nltk/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"System Version: {}\\n\".format(sys.version))\n",
    "print(nltk.__file__) #print location of nltk packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in Reviews and Categories to Tuple and convert to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plot, :, two, teen, couples, go, to, a, churc...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, happy, bastard, ', s, quick, movie, revi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[it, is, movies, like, these, that, make, a, j...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\", quest, for, camelot, \", is, warner, bros, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[synopsis, :, a, mentally, unstable, man, unde...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Label\n",
       "0  [plot, :, two, teen, couples, go, to, a, churc...   neg\n",
       "1  [the, happy, bastard, ', s, quick, movie, revi...   neg\n",
       "2  [it, is, movies, like, these, that, make, a, j...   neg\n",
       "3  [\", quest, for, camelot, \", is, warner, bros, ...   neg\n",
       "4  [synopsis, :, a, mentally, unstable, man, unde...   neg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(documents), columns=[\"Review\",\"Label\"])\n",
    "df['Review'].str.lower()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Value Count and Add Dummy Variable to Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plot, :, two, teen, couples, go, to, a, churc...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, happy, bastard, ', s, quick, movie, revi...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[it, is, movies, like, these, that, make, a, j...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\", quest, for, camelot, \", is, warner, bros, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[synopsis, :, a, mentally, unstable, man, unde...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Label\n",
       "0  [plot, :, two, teen, couples, go, to, a, churc...   neg\n",
       "1  [the, happy, bastard, ', s, quick, movie, revi...   neg\n",
       "2  [it, is, movies, like, these, that, make, a, j...   neg\n",
       "3  [\", quest, for, camelot, \", is, warner, bros, ...   neg\n",
       "4  [synopsis, :, a, mentally, unstable, man, unde...   neg"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    1000\n",
       "neg    1000\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#series method to count values\n",
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Replace Labels with dummy variables\n",
    "df['Label'].replace(['pos','neg'],[1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into Testing and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def traintest_split(df):\n",
    "    training,testing = train_test_split(df,test_size=0.15,random_state=1)\n",
    "    X_train, y_train = training.iloc[:,0], training.iloc[:,1]\n",
    "    X_test, y_test = testing.iloc[:,0], testing.iloc[:,1]\n",
    "    return(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In order to input into countvectorizer(), must use 1D series (both x and y). X should be 1D becasue it's going to be transformed to 2D by countvectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obserbations: 2000\n",
      "X_train size: 1700 -- y_train size: 1700\n",
      "X_test size: 300 -- y_test size: 300\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test = traintest_split(df)\n",
    "print(\"Number of obserbations: {}\".format(len(df['Review'])))\n",
    "print(\"X_train size: {} -- y_train size: {}\".format(X_train.shape[0],y_train.shape[0]))\n",
    "print(\"X_test size: {} -- y_test size: {}\".format(X_test.shape[0],y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bag of Words:\n",
    "\n",
    "- Create Document Term Matrix and train model on (i.e. this gives us \"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Vocabulary Words in Document Term Matrix: 36971\n"
     ]
    }
   ],
   "source": [
    "def get_document_term_matrix_train_test(X_train,X_test):\n",
    "    vect = CountVectorizer(stop_words='english',lowercase=True)\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "    df_dtm = pd.DataFrame(X_train_dtm.toarray(),columns=vect.get_feature_names())\n",
    "    #X_test is transformed to document term matrix \n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    return(X_train_dtm,X_test_dtm,df_dtm)\n",
    "\n",
    "df_dtm = get_document_term_matrix_train_test(X_train,X_test)[2]\n",
    "print(\"Number of Vocabulary Words in Document Term Matrix: {}\".format(df_dtm.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: cannot reconstruct original \"reviews\" from the transformation. Only do a transform on the testing --> not fit on testing set. If word is not seen in model training then it is dropped in order to mantain the dimensions of the document term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0009f</th>\n",
       "      <th>007</th>\n",
       "      <th>00s</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>05425</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zundel</th>\n",
       "      <th>zus</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "      <th>zycie</th>\n",
       "      <th>zzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36971 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0009f  007  00s  03  04  05  05425  10   ...     zuko  zukovsky  \\\n",
       "0   0    0      0    0    0   0   0   0      0   0   ...        0         0   \n",
       "1   0    0      0    0    0   0   0   0      0   0   ...        0         0   \n",
       "2   0    0      0    0    0   0   0   0      0   0   ...        0         0   \n",
       "3   0    0      0    0    0   0   0   0      0   0   ...        0         0   \n",
       "4   0    0      0    0    0   0   0   0      0   0   ...        0         0   \n",
       "\n",
       "   zulu  zundel  zus  zweibel  zwick  zwigoff  zycie  zzzzzzz  \n",
       "0     0       0    0        0      0        0      0        0  \n",
       "1     0       0    0        0      0        0      0        0  \n",
       "2     0       0    0        0      0        0      0        0  \n",
       "3     0       0    0        0      0        0      0        0  \n",
       "4     0       0    0        0      0        0      0        0  \n",
       "\n",
       "[5 rows x 36971 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dtm.head() #print first 5 rows of DTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Evaluating Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [MultinomialNB(),LogisticRegression(),SVC(),LinearSVC()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def test_model(classifiers,df):\n",
    "    \n",
    "        start = time.time()\n",
    "        \n",
    "        #split data up into training and testing sets:\n",
    "        X_train,y_train,X_test,y_test = traintest_split(df)\n",
    "\n",
    "        #Generate Document Term Matrix & X_test is transformed to document term matrix \n",
    "        X_train_dtm, X_test_dtm, df_dtm = get_document_term_matrix_train_test(X_train,X_test)\n",
    "        print(\"*****Training Set*****:\")\n",
    "        print(\"Vocabulary Words: {}\".format(X_train_dtm.shape[1]))\n",
    "        print(\"Total Documents: {}\".format(X_train_dtm.shape[0]))\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "        print(\"*****Testing Set*****:\")\n",
    "        print(\"Vocabulary Words: {}\".format(X_test_dtm.shape[1]))\n",
    "        print(\"Total Documents: {}\".format(X_test_dtm.shape[0]))\n",
    "\n",
    "        clf.fit(X_train_dtm,y_train)\n",
    "\n",
    "        #Make prediction on the testing set:\n",
    "        y_pred_class = clf.predict(X_test_dtm)\n",
    "\n",
    "        #Accuracy Score\n",
    "        acc = metrics.accuracy_score(y_test,y_pred_class)*100\n",
    "        print(\"Accuracy: {}\".format(np.round(acc,3)))\n",
    "            \n",
    "        #confusion matrix\n",
    "        #conf_matrix = metrics.confusion_matrix(y_test,y_pred_class)\n",
    "        \n",
    "        end = time.time()\n",
    "        total_time = end-start\n",
    "        m,s = divmod(total_time,60)\n",
    "        h,m = divmod(m,60)\n",
    "        time_format = \"%d:%02d:%02d\" % (h,m,s)\n",
    "        print(\"Total Time: {}\".format(time_format))\n",
    "        return(clf_name,acc,time_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "MultinomialNB\n",
      "==================================\n",
      "\n",
      "Iteration:1\n",
      "*****Training Set*****:\n",
      "Vocabulary Words: 36971\n",
      "Total Documents: 1700\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "*****Testing Set*****:\n",
      "Vocabulary Words: 36971\n",
      "Total Documents: 300\n",
      "Accuracy: 77.333\n",
      "Total Time: 0:00:02\n",
      "\n",
      "\n",
      "==================================\n",
      "LogisticRegression\n",
      "==================================\n",
      "\n",
      "Iteration:1\n",
      "*****Training Set*****:\n",
      "Vocabulary Words: 36971\n",
      "Total Documents: 1700\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "*****Testing Set*****:\n",
      "Vocabulary Words: 36971\n",
      "Total Documents: 300\n",
      "Accuracy: 81.0\n",
      "Total Time: 0:00:02\n",
      "\n",
      "\n",
      "==================================\n",
      "SVC\n",
      "==================================\n",
      "\n",
      "Iteration:1\n",
      "*****Training Set*****:\n",
      "Vocabulary Words: 36971\n",
      "Total Documents: 1700\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "*****Testing Set*****:\n",
      "Vocabulary Words: 36971\n",
      "Total Documents: 300\n",
      "Accuracy: 52.333\n",
      "Total Time: 0:00:10\n",
      "\n",
      "\n",
      "==================================\n",
      "LinearSVC\n",
      "==================================\n",
      "\n",
      "Iteration:1\n",
      "*****Training Set*****:\n",
      "Vocabulary Words: 36971\n",
      "Total Documents: 1700\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "*****Testing Set*****:\n",
      "Vocabulary Words: 36971\n",
      "Total Documents: 300\n",
      "Accuracy: 80.333\n",
      "Total Time: 0:00:02\n",
      "\n",
      "\n",
      "\n",
      "**Results**\n",
      "                 Model   Accuracy Run Time\n",
      "0       MultinomialNB  77.333333  0:00:02\n",
      "1  LogisticRegression  81.000000  0:00:02\n",
      "2                 SVC  52.333333  0:00:10\n",
      "3           LinearSVC  80.333333  0:00:02\n",
      "\n",
      "-----------------------------\n",
      "Mean Results\n",
      "-----------------------------\n",
      "Average Accuracy Model\n",
      "LinearSVC             80.333333\n",
      "LogisticRegression    81.000000\n",
      "MultinomialNB         77.333333\n",
      "SVC                   52.333333\n",
      "Name: Accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(columns=['Model','Accuracy','Run Time'])\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    print(\"==================================\")\n",
    "    print(clf_name)\n",
    "    print(\"==================================\")\n",
    "    for i in range(0,1):\n",
    "        print(\"\\nIteration:{}\".format(i+1))\n",
    "        clf_name,acc,time_format = test_model(clf,df)\n",
    "        df_results = df_results.append({'Model':clf_name,\n",
    "                                        'Accuracy':acc,\n",
    "                                        'Run Time':time_format},ignore_index=True)\n",
    "    print(\"\\n\")\n",
    "print(\"\\n**Results**\\n\",df_results)\n",
    "print()\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "print(\"Mean Results\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "avg_acc = df_results['Accuracy'].groupby(df_results['Model']).mean()\n",
    "print(\"Average Accuracy\", avg_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test_model_cross_val(classifiers,X_train,y_train,X_test,y_test):\n",
    "    \n",
    "        start = time.time()\n",
    "\n",
    "        #Generate Document Term Matrix & X_test is transformed to document term matrix \n",
    "        X_train_dtm, X_test_dtm, df_dtm = get_document_term_matrix_train_test(X_train,X_test)\n",
    "        \n",
    "        clf.fit(X_train_dtm,y_train)\n",
    "\n",
    "        #Make prediction on the testing set:\n",
    "        y_pred_class = clf.predict(X_test_dtm)\n",
    "\n",
    "        #Accuracy Score\n",
    "        acc = metrics.accuracy_score(y_test,y_pred_class)*100\n",
    "        print(\"Accuracy: {}\".format(np.round(acc,3)))\n",
    "                \n",
    "        end = time.time()\n",
    "        total_time = end-start\n",
    "        m,s = divmod(total_time,60)\n",
    "        h,m = divmod(m,60)\n",
    "        time_format = \"%d:%02d:%02d\" % (h,m,s)\n",
    "        print(\"Total Time: {}\".format(time_format))\n",
    "        \n",
    "        #confusion matrix\n",
    "        conf_matrix = metrics.confusion_matrix(y_test,y_pred_class)\n",
    "        print(\"\\nConfusion Matrix:\",conf_matrix)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        return(acc,time_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Fold CrossValidaiton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Model: MultinomialNB -- K-Fold Cross-Validation\n",
      "**************************************************\n",
      "\n",
      "Fold: 1\n",
      "Train_Index:[ 4  5  6  7  9 10 12 13 14]....\n",
      "Test_Index: [ 1  3  8 11 16 17 19 22 30]....\n",
      "Accuracy: 81.859\n",
      "Total Time: 0:00:02\n",
      "\n",
      "Confusion Matrix: [[270  59]\n",
      " [ 62 276]]\n",
      "\n",
      "\n",
      "==========================================\n",
      "\n",
      "Fold: 2\n",
      "Train_Index:[ 1  3  4  7  8 11 15 16 17]....\n",
      "Test_Index: [ 5  6  9 10 12 13 14 23 26]....\n",
      "Accuracy: 83.658\n",
      "Total Time: 0:00:02\n",
      "\n",
      "Confusion Matrix: [[291  48]\n",
      " [ 61 267]]\n",
      "\n",
      "\n",
      "==========================================\n",
      "\n",
      "Fold: 3\n",
      "Train_Index:[ 1  2  3  5  6  8  9 10 11]....\n",
      "Test_Index: [ 7 15 18 20 21 24 25 29 36]....\n",
      "Accuracy: 84.835\n",
      "Total Time: 0:00:02\n",
      "\n",
      "Confusion Matrix: [[287  45]\n",
      " [ 56 278]]\n",
      "\n",
      "\n",
      "==========================================\n",
      "\n",
      "Mean Accuracy = 83.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"**************************************************\")\n",
    "print(\"Model: {} -- K-Fold Cross-Validation\".format(classifier.__class__.__name__))\n",
    "print(\"**************************************************\\n\")\n",
    "\n",
    "x = df.iloc[:,0]\n",
    "y = df.iloc[:,1]\n",
    "fold = 0\n",
    "accuracy = []\n",
    "\n",
    "KF = KFold(len(df),3, random_state=1, shuffle=True)\n",
    "for index, (train_index, test_index) in list(enumerate(KF,start=1)):\n",
    "    print(\"Fold: {}\".format(index))\n",
    "    print(\"Train_Index:{}....\".format(train_index[1:10]))\n",
    "    print(\"Test_Index: {}....\".format(test_index[1:10]))\n",
    "    X_train = x.loc[train_index]; X_test= x.loc[test_index]\n",
    "    y_train = y.loc[train_index];y_test = y.loc[test_index]\n",
    "    acc,time_format = test_model_cross_val(classifiers,X_train,y_train,X_test,y_test)\n",
    "    accuracy.append(acc)\n",
    "    print(\"==========================================\\n\")\n",
    "print(\"Mean Accuracy = {}%\".format(round(np.mean(accuracy))))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
